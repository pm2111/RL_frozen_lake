{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6049516-8449-481c-bb4d-66cefa61f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import gym\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5380f9",
   "metadata": {},
   "source": [
    "Choose the environment that the agent will explore and train on. \n",
    "In our case, we choose a 4x4 grid of icy lake with holes where the agent can fall into.\n",
    "Success in our case is defined as the successful crossing of the icy lake without falling into holes.\n",
    "![convert notebook to web app](https://www.gymlibrary.dev/_images/frozen_lake.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266befb5-6e37-41f6-8ffe-ef7563e37a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 4\n",
    "env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae2e90",
   "metadata": {},
   "source": [
    "Below we define the functions used in the learning process. The idea is to propagate the information from the exploring agent throughout the state-value and action value functions. The implementation follows the notions from the Sutton and Barto RL learning textbook. In fewer than 10 iterations, the algorithm learns to navigate around the maze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2619d6a5-6bc9-4e32-b961-b0e1d7234ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_states(current_state,horizontal_grid_size,vertical_grid_size):\n",
    "    y_pos = np.mod(current_state,vertical_grid_size)\n",
    "    x_pos = int(current_state/horizontal_grid_size)\n",
    "    y_positions = np.array([y_pos+1, y_pos, y_pos-1,y_pos])\n",
    "    x_positions = np.array([x_pos,x_pos-1,x_pos,x_pos+1])\n",
    "    do_not_keep = (x_positions <0)| (x_positions>horizontal_grid_size-1)| (y_positions < 0 ) | (y_positions > vertical_grid_size-1)\n",
    "\n",
    "    \n",
    "    keep_y = np.where((x_positions <0)|(x_positions>horizontal_grid_size-1), x_positions, x_positions[x_pos])+1 ==1\n",
    "\n",
    "    x_positions = x_positions[do_not_keep==False]\n",
    "    y_positions = y_positions[do_not_keep==False]\n",
    "    \n",
    "    state_indices = x_positions*vertical_grid_size + np.mod(y_positions,horizontal_grid_size)\n",
    "    return state_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7a822e-999a-477e-bfdd-31c939654689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_policy_iteration(delta_thresh, value_thresh):\n",
    "\n",
    "    env = init_env()\n",
    "    policy = init_policy()\n",
    "    state_values = calculate_state_values(policy, env, value_thresh)\n",
    "    delta = delta_thresh\n",
    "    \n",
    "    while delta >= delta_thresh:\n",
    "        policy = update_policy(policy, state_values)\n",
    "        new_state_values = calculate_state_values(policy, env, value_thresh)\n",
    "        delta = state_values - new_state_values\n",
    "        state_values = new_state_values\n",
    "    return policy\n",
    "    \n",
    "def init_state_values(n):\n",
    "    \"\"\"\n",
    "    Initializes values to zeros for all states\n",
    "    where n is the number of states\n",
    "    \"\"\"\n",
    "    return np.zeros(n)\n",
    "\n",
    "def calculate_state_values(env, delta_thresh=0.001, gamma=0.9):\n",
    "    \n",
    "    env.reset()\n",
    "    env.unwrapped.s = 0 # begin at the upper left corner\n",
    "    state_values = init_state_values(env.observation_space.n)\n",
    "    deltas = np.ones(env.observation_space.n)*1000 # compute deltas for each state\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    \n",
    "    while deltas.max() >= delta_thresh:\n",
    "        for state in range(env.observation_space.n): # iterate sequentially over state space\n",
    "            env.reset()\n",
    "            env.unwrapped.s = state\n",
    "            action_value_estimate = {} # action value for current state stored as action:value pairs\n",
    "            for action in range(env.action_space.n):\n",
    "                \n",
    "                new_state, reward, terminated, _ = env.step(action)\n",
    "                \n",
    "                env.unwrapped.s = state # move the agent back to the state being computed\n",
    "\n",
    "                if terminated == 1:\n",
    "                    action_value_estimate[action] = (reward + (gamma*state_values[new_state]))\n",
    "                else:\n",
    "                    action_value_estimate[action] = (reward + (gamma*state_values[new_state]))\n",
    "\n",
    "            best_value = max(action_value_estimate.values())\n",
    "            \n",
    "            deltas[state] = abs(state_values[state] - best_value)\n",
    "            state_values[state] = best_value\n",
    "\n",
    "            \n",
    "        i += 1\n",
    "            \n",
    "    return state_values\n",
    "\n",
    "def calculate_policy(env, delta_thresh=0.001, gamma=0.9):\n",
    "    \n",
    "    env.reset()\n",
    "    env.unwrapped.s = 0 # begin at the upper left corner\n",
    "    state_values = init_state_values(env.observation_space.n)\n",
    "    deltas = np.ones(env.observation_space.n)*1000 # compute deltas for each state\n",
    "    action_values = {}\n",
    "    i = 0\n",
    "    \n",
    "    \n",
    "    while deltas.max() >= delta_thresh:\n",
    "        for state in range(env.observation_space.n): # iterate sequentially over state space\n",
    "            env.reset()\n",
    "            env.unwrapped.s = state\n",
    "            action_value_estimate = {} # action value for current state stored as action:value pairs\n",
    "            for action in range(env.action_space.n):\n",
    "                \n",
    "                new_state, reward, terminated, _ = env.step(action)\n",
    "                \n",
    "                env.unwrapped.s = state # move the agent back to the state being computed\n",
    "\n",
    "                action_value_estimate[action] = (reward + (gamma*state_values[new_state]))\n",
    "                \n",
    "            action_values[state] = action_value_estimate #store action values\n",
    "            best_value = max(action_value_estimate.values())\n",
    "            \n",
    "            deltas[state] = abs(state_values[state] - best_value)\n",
    "            state_values[state] = best_value\n",
    "\n",
    "            \n",
    "        i += 1\n",
    "            \n",
    "    return action_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a50e5",
   "metadata": {},
   "source": [
    "Finally, we run the algorithm to compute the value of each state and the associated action values.\n",
    "It converges quickly and the results are stored in dictoionaries below. The heatmap below shows that its very advantageous to be in state (2,3) which is the pre-terminal state of the grid and not very advantageous to be in the ice holes, marked by black colour. The state value does not update upon termination, hence the state value of the terminal goal state (3,3) remains low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4bbc7f4-328d-4114-b67a-7be4e56e1d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state_values = calculate_state_values(env)\n",
    "action_values = calculate_policy(env, delta_thresh=0.1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f24abbe-305d-4e33-9cc0-b5d89eb3b3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "sb.heatmap(state_values.reshape((4,4))).set(title= \"State values for the grid\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
